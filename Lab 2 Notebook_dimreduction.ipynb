{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import offsetbox\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.ticker import NullFormatter\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "\n",
    "import sklearn\n",
    "from sklearn import decomposition, manifold, cluster, datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import Isomap, MDS\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import fetch_openml, fetch_lfw_people\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_blobs, load_digits\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dimensionality Reduction\n",
    "----------------------\n",
    "## a. Principal Component Analysis:\n",
    "----------------------\n",
    "### PCA(n_components = None, whitten = False, svd_solver = 'auto', tol = 0.0)\n",
    "* linear dimensionality reduction using Singular Value Decomposition of the data to project it to a lower dimensional space.\n",
    "* The input data is centered but not scaled for each feature before applying the SVD.\n",
    "* #### Arguments: only \"n_components\" matters for now\n",
    " 1.         n_components: number of components to keep. If not set: all components are kept.\n",
    "            if 0 < n_components < 1 and svd_solver = 'full' : select the number of components :\n",
    "            the amount of variance that needs to be explained is greater than the percentage specified by n_components.\n",
    "  2.         whitten: when True - the components_ vectors are multiplied by the square root of n_samples and divided by singular values to ensure uncorrelated outputs with uni component-wise variances.\n",
    "  3.       svd_solver: \"auto\", \"full\", \"arpack\", \"randomized\"\n",
    "  4.         tol: tolerance for singular values computed by svd_solver = \"arpack\"\n",
    "* #### Artributes: (of the PCA object)\n",
    " *         components_: Principal axes in feature space, representation the directions of maximm variance in the data.\n",
    " *         explained_variance_: The amount of variance explained by each of the selected components\n",
    " *         explained_variance_ratio_: percentage of variance explained by each of the selected components\n",
    " *         singular_values_: The singular values corresponding to each of the selected components.\n",
    " *         mean_: Per-feature empirical mean, estimated from the training set.\n",
    " *         n_components_: The estimated number of components\n",
    "* #### Methods: (on the PCA object)\n",
    " *         fit(X): fit the model for dataset X\n",
    " *         fit_transform(X): fit the model for dataset X and apply the dimensionality reduction on X, return the reduced X'\n",
    " *         get_covariance(X): compute data covariance with the generative model\n",
    " *         transform(X): apply dimensionality reduction for dataset X\n",
    " *         inverse_transform(X): transform data back to its original space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISES\n",
    "# Ex 2.a.1: Iris dataset visualization with Principal Component Analysis\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "# load dataset into Pandas DataFrame\n",
    "df = pd.read_csv(url, names=['sepal length','sepal width','petal length','petal width','target'])\n",
    "\n",
    "features = ['sepal length', 'sepal width', 'petal length', 'petal width']\n",
    "\n",
    "# Separating out the features\n",
    "x = df.loc[:, features].values\n",
    "# Separating out the target\n",
    "y = df.loc[:,['target']].values\n",
    "# Standardizing the features\n",
    "x = StandardScaler().fit_transform(x)\n",
    "\n",
    "# Let's take a look at the first 5 data entries of the Iris dataset.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex 2.a.1: Iris dataset visualization with Principal Component Analysis (cont)\n",
    "\n",
    "# PCA Projection to 2D\n",
    "### YOUR CODE HERE (Fill in the \"None\"). 2 lines of code\n",
    "# Hint: variable \"principalComponents\" must be the reduced data.\n",
    "None \n",
    "principalComponents = None\n",
    "### END OF YOUR CODE\n",
    "\n",
    "# Construct the Data Frame for the reduced data.\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "principalDf.head()\n",
    "\n",
    "# Concatenate the reduced Data Frame with the column \"target\"\n",
    "finalDf = pd.concat([principalDf, df[['target']]], axis = 1)\n",
    "\n",
    "# Visualize the projection onto the 2 dimensions of the principalComponents\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2 component PCA', fontsize = 20)\n",
    "targets = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
    "colors = ['r', 'g', 'b']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = finalDf['target'] == target\n",
    "    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
    "               , finalDf.loc[indicesToKeep, 'principal component 2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "ax.legend(targets)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex 2.a.2: Variance ratio by the principal components\n",
    "\n",
    "# Data: 10 features\n",
    "X1, Y1 = make_blobs(n_features=10, n_samples=100, centers=4, random_state=4, cluster_std=2)\n",
    "# Verify the number of dimensions \n",
    "print(X1.shape)\n",
    "\n",
    "# Principal Component Analysis into 4 components\n",
    "### YOUR CODE HERE (Fill in the \"None\"). 2 lines of code.\n",
    "# Hint: variable \"PrincipalComponents\" should be the dimension-reduced data\n",
    "None\n",
    "PrincipalComponents = None\n",
    "### END OF YOUR CODE\n",
    "\n",
    "pc_df = pd.DataFrame(data = PrincipalComponents , columns = ['PC1', 'PC2','PC3','PC4'])\n",
    "pc_df['Cluster'] = Y1\n",
    "pc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex 2.a.2: Variance ratio by the principal components (cont)\n",
    "\n",
    "# We want to see the relative contribution of the variances corresponding to the components\n",
    "### YOUR CODE HERE (Fill in the \"None\")\n",
    "# Hint: which attribute of the PCA object should we use?\n",
    "variance_ratio = None\n",
    "### END OF YOUR CODE\n",
    "\n",
    "df = pd.DataFrame({'Explained Variance Ratio':variance_ratio,\n",
    "             'Principal Components':['PC1','PC2','PC3','PC4']})\n",
    "sns.barplot(x='Principal Components',y=\"Explained Variance Ratio\", data=df, color=\"c\");\n",
    "\n",
    "### QUESTION: based on this plot, can we reduce further the number of components?\n",
    "### ANSWER: the first 2 components almost dominate the others, we can further reduce to 2 components without losing much information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex 2.a.2: Variance ratio by the principal components (cont)\n",
    "\n",
    "principalca = PCA(n_components=2)\n",
    "PrincipalComponents = principalca.fit_transform(X1)\n",
    "\n",
    "# Compute K-means clustering\n",
    "### YOUR CODE HERE\n",
    "None\n",
    "# Hint: Variable \"y_pred\" should be cluster indices of samples\n",
    "y_pred = None\n",
    "### END OF YOUR CODE\n",
    "\n",
    "## Visualization\n",
    "plt.scatter(PrincipalComponents[:, 0], PrincipalComponents[:, 1], c=y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex 2.a.3 Image Compression\n",
    "\n",
    "# Consider the MNIST dataset (hand-written digit)\n",
    "mnist = fetch_openml('mnist_784', version = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex 2.a.3 Image Compression (cont)\n",
    "\n",
    "# Extract the images and labels \n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "\n",
    "# Size of the dataset \n",
    "print(X.shape)\n",
    "\n",
    "# Show 1 sample image\n",
    "some_digit = X[0]\n",
    "some_digit_image = some_digit.reshape(28, 28)\n",
    "plt.imshow(some_digit_image, cmap = mpl.cm.binary, interpolation = \"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex 2.a.3 Image Compression (cont)\n",
    "\n",
    "# So we can see that there are 70,000 samples (images) and each sample size of size 784 = 28 x28, equivalently 784 features\n",
    "# Our goal is to apply dimensionality reduction to reduce the amount of space needed\n",
    "# But at the same time, retain most of the variance explained\n",
    "\n",
    "# We consider a subset of the MNIST dataset\n",
    "X_train = X[:10000,:]\n",
    "\n",
    "# PCA keeping 95% of the variance explained\n",
    "### YOUR CODE HERE (Fill in the \"None\"). 2 lines of code\n",
    "# Hint: variable \"X_reduced\" should be the dimensionality-reduced result of X_train\n",
    "None\n",
    "X_reduced = None\n",
    "### END OF YOUR CODE\n",
    "\n",
    "# Size of the dimension-reduced data\n",
    "print(X_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex 2.a.3 Image Compression (cont)\n",
    "\n",
    "# We can see that the number of features in each sample of X_reduced is only 150, much smaller than the original value 784\n",
    "# while at the same time, X_reduced retains 95% of the variance explained by X_train\n",
    "\n",
    "# Let's see with 95% explained variance preserved, how does PCA affect the resolution of the images\n",
    "\n",
    "# Compare the original images vs. the dimensionality-reduced images\n",
    "# Create the dimension-reduced dataset by PCA\n",
    "### YOUR CODE HERE (Fill in the \"None\"). 2 lines of code\n",
    "# Hint: variable \"X_dim_reduced\" should be the dimension-reduced dataset\n",
    "None\n",
    "X_dim_reduced = None\n",
    "### END OF YOUR CODE\n",
    "\n",
    "# X_dim_reduced is the projection of X_train onto a space of 169 dimensions\n",
    "# In order to compare in terms of images, we need to reconstruct the 28x28 image data\n",
    "# Reconstruct the image data:\n",
    "### YOUR CODE HERE (Fill in the \"None\")\n",
    "X_recovered = None\n",
    "### END OF YOUR CODE\n",
    "\n",
    "fig=plt.figure(figsize=(8, 8))\n",
    "columns = 2\n",
    "rows = 5\n",
    "for i in range(1, columns*rows + 1):\n",
    "    if i % 2 == 1:     # Show the original images on the left column\n",
    "        original_digit = X_train[i//2]\n",
    "        original_digit_image = original_digit.reshape(28,28)\n",
    "        #original_digit_image = original_digit_image.reshape(12,12)\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.imshow(original_digit_image, cmap = mpl.cm.binary, interpolation = \"nearest\")\n",
    "    else:              # Show the recovered images on the right column\n",
    "        reduced_digit = X_recovered[(i-1)//2]\n",
    "        reduced_digit_image = reduced_digit.reshape(28,28)\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.imshow(reduced_digit_image, cmap = mpl.cm.binary, interpolation = \"nearest\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "### Optional exercise: further reduce the number of dimensions until the recovered images are no longer intact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex 2.a.3 Image Compression (cont)\n",
    "\n",
    "# While the dimension-reduced-recoved images clearly have lower resolutions, the images are still mostly intact\n",
    "# and we can still recognize the digits while the dimension is significantly reduced from 784 to 150\n",
    "\n",
    "# EXTRA: Visualization of the Explained Variance as a function of the number of dimensions\n",
    "pca = PCA().fit(X_train)\n",
    "\n",
    "dimensions = range(1,785)\n",
    "variance_ratio =np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "plt.figure(figsize = (15,5))\n",
    "plt.xticks(np.arange(0, 800, step=50))\n",
    "plt.plot(dimensions, variance_ratio)\n",
    "plt.plot(dimensions[154], variance_ratio[154], 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dimensionality Reduction (cont)\n",
    "------------------------\n",
    "## b. Manifold Isomap Embedding :\n",
    "------------------------\n",
    "### Isomap(n_neighbors, n_components, eigen_solver, max_ter)\n",
    "* Non-linear dimensionality reduction through Isometric Mapping\n",
    "* #### Arguments: \n",
    " 1.         n_neighbors: number of neighbors to consider for each point\n",
    " 2.         n_components: number of coordinates for the manifold\n",
    " 3.        eigen_solver: choose the solver\n",
    "  *                     \"auto\": choose the most efficient solver \n",
    "  *                      \"arpack\": Arnoldi decomposition to find the eigenvalues and eigenvectors\n",
    "  *                      \"dense\": direct solver (i.e LAPACK) for the eigenvalue decomposition\n",
    " 4.         max_iter: maximum number of iterations for the arpack solver. not used when eigen_solver = \"dense\"\n",
    "* #### Artributes: (of the Isomap object)\n",
    " *         embedding_: store the embedding vectors, shape (n_samples, n_components)\n",
    " *        kernel_pca: the KernelPCA object used to implement the embedding \n",
    " *   training_data: store the training data, (n_samples, n_features)\n",
    "* #### Methods: (on the PCA object)\n",
    " *         fit(X): compute the embedding vectors for dataset X\n",
    " *         fit_transform(X): fit the model from data in dataset X and transform X\n",
    " *        transform(X): transform X\n",
    " *         get_params(): get parameters for this estimator\n",
    " *         reconstruction_error : compute the reconstruction error for the embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE\n",
    "# Ex.2.b.1: Digit recognition using Isomap Embedding:\n",
    "\n",
    "# Load the digit images\n",
    "digits = datasets.load_digits(n_class=6)\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "# Plot images of the digits\n",
    "n_img_per_row = 20\n",
    "img = np.zeros((10 * n_img_per_row, 10 * n_img_per_row))\n",
    "for i in range(n_img_per_row):\n",
    "    ix = 10 * i + 1\n",
    "    for j in range(n_img_per_row):\n",
    "        iy = 10 * j + 1\n",
    "        img[ix:ix + 8, iy:iy + 8] = X[i * n_img_per_row + j].reshape((8, 8))\n",
    "plt.figure(figsize = (8,8))\n",
    "plt.imshow(img, cmap=plt.cm.binary)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('A selection from the 64-dimensional digits dataset')\n",
    "\n",
    "# Scale and visualize the embedding vectors\n",
    "def plot_embedding(X, title=None):\n",
    "    x_min, x_max = np.min(X, 0), np.max(X, 0)\n",
    "    X = (X - x_min) / (x_max - x_min)\n",
    "\n",
    "    plt.figure(figsize = (10,7))\n",
    "    ax = plt.subplot(111)\n",
    "    for i in range(X.shape[0]):\n",
    "        plt.text(X[i, 0], X[i, 1], str(y[i]),\n",
    "                 color=plt.cm.Set1(y[i] / 10.),\n",
    "                 fontdict={'weight': 'bold', 'size': 9})\n",
    "\n",
    "    if hasattr(offsetbox, 'AnnotationBbox'):\n",
    "        # only print thumbnails with matplotlib > 1.0\n",
    "        shown_images = np.array([[1., 1.]])  # just something big\n",
    "        for i in range(X.shape[0]):\n",
    "            dist = np.sum((X[i] - shown_images) ** 2, 1)\n",
    "            if np.min(dist) < 4e-3:\n",
    "                # don't show points that are too close\n",
    "                continue\n",
    "            shown_images = np.r_[shown_images, [X[i]]]\n",
    "            imagebox = offsetbox.AnnotationBbox(\n",
    "                offsetbox.OffsetImage(digits.images[i], cmap=plt.cm.gray_r),\n",
    "                X[i])\n",
    "            ax.add_artist(imagebox)\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    if title is not None:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex.2.b.1: Digit recognition using Isomap Embedding (cont)\n",
    "\n",
    "# IsoMap Embedding into a 2D space, 30 neighbors to consider for each point\n",
    "### YOUR CODE HERE (Fill in the \"None\")\n",
    "# Hint: the \"X_iso\" must be the transformed data\n",
    "None\n",
    "X_iso = None\n",
    "### END OF YOUR CODE\n",
    "\n",
    "# Plot the Isomap embedding result\n",
    "plot_embedding(X_iso, \"Isomap projection of the digits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex.2.b.2: Isomap on Face images \n",
    "\n",
    "# Load the face images (it may take several images)\n",
    "faces = fetch_lfw_people(min_faces_per_person=30)\n",
    "faces.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex.2.b.2: Isomap on Face images (cont)\n",
    "\n",
    "# Show some images\n",
    "fig, ax = plt.subplots(4, 8, subplot_kw=dict(xticks=[], yticks=[]))\n",
    "for i, axi in enumerate(ax.flat):\n",
    "    axi.imshow(faces.images[i], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex.2.b.2: Isomap on Face images (cont)\n",
    "\n",
    "# Load the face images\n",
    "X = faces.data\n",
    "\n",
    "# Isomap for X \n",
    "### YOUR CODE HERE (Fill in the \"None\")\n",
    "# Hint: the \"proj\" variable must be the transformed data\n",
    "None\n",
    "proj = None\n",
    "### END OF YOUR CODE\n",
    "\n",
    "# Plot the embedded images\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "images = faces.images[:,::2,::2]\n",
    "thumb_frac = 0.05\n",
    "cmap = 'gray'\n",
    "ax = ax or plt.gca()\n",
    "    \n",
    "ax.plot(proj[:, 0], proj[:, 1], '.k')\n",
    "    \n",
    "if images is not None:\n",
    "    min_dist_2 = (thumb_frac * max(proj.max(0) - proj.min(0))) ** 2\n",
    "    shown_images = np.array([2 * proj.max(0)])\n",
    "    for i in range(X.shape[0]):\n",
    "        dist = np.sum((proj[i] - shown_images) ** 2, 1)\n",
    "        if np.min(dist) < min_dist_2:\n",
    "            # don't show points that are too close\n",
    "            continue\n",
    "        shown_images = np.vstack([shown_images, proj[i]])\n",
    "        imagebox = offsetbox.AnnotationBbox(\n",
    "            offsetbox.OffsetImage(images[i], cmap=cmap),\n",
    "                                      proj[i])\n",
    "        ax.add_artist(imagebox)\n",
    "        \n",
    "# QUESTION: What can you see from how the images are mapped in the plot?\n",
    "# ANSWER: Left to right: lightness and darkness; bottom to top: general orientation of the faces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dimensionality Reduction (cont)\n",
    "----------------------------\n",
    "## c. Manifold Multidimensional scaling\n",
    "----------------------------\n",
    "### MDS(n_components, metric, max_iter)\n",
    "* Non-linear dimensionality reduction through Isometric Mapping\n",
    "* #### Arguments: \n",
    " 1.         n_components: number of coordinates for the manifold\n",
    " 2.         metric: perform metric MDS with \"True\", nonmetric MDS otherwise.\n",
    " 3.         max_iter: maximum number of iterations for a single run\n",
    "* #### Artributes: (of the Isomap object)\n",
    " *         embedding_: store the position of the dataset in the embedding space\n",
    " *         stress_: final value of sum of squared distance of dispanrities and distances for all constrained points\n",
    "* #### Methods: (on the PCA object)\n",
    " *         fit(X): compute the podiyion of the points in the embedding space\n",
    " *         fit_transform(X): fit the data for dataset X, and return the embedded coordinates\n",
    " *         get_params(): get parameters for this estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE:\n",
    "\n",
    "# Ex 2.c.1: Digit recognition using MDS (Same Dataset with Exercise 2.b.1)\n",
    "# Since we are re-using the function \"plot_embedding()\" function, please do not restart the notebook\n",
    "\n",
    "# Load the digit images\n",
    "digits = datasets.load_digits(n_class=6)\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "# MDS for the dataset X, into a 2D space. (100 iterations)\n",
    "### YOUR CODE HERE (fill in the \"None\")\n",
    "# Hint: X_mds must be the MDS-transformed data\n",
    "None \n",
    "X_mds = None\n",
    "### END OF YOUR CODE\n",
    "\n",
    "# Plot our embedding\n",
    "plot_embedding(X_mds, \"MDS embedding of the digits (time %.2fs)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex 2.c.2: IsoMap vs. MDS\n",
    "# This Exercise illustrates the significant results of ISOMap and MDS when reducing from dimension 3 to 2\n",
    "\n",
    "# Next line to silence pyflakes. This import is needed.\n",
    "Axes3D\n",
    "\n",
    "n_points = 1000\n",
    "X, color = datasets.samples_generator.make_s_curve(n_points, random_state=0)\n",
    "n_neighbors = 10\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(15, 8))\n",
    "plt.suptitle(\"Manifold Learning with %i points, %i neighbors\"\n",
    "             % (1000, n_neighbors), fontsize=14)\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(131, projection='3d')\n",
    "ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=color, cmap=plt.cm.Spectral)\n",
    "ax.view_init(4, -72)\n",
    "\n",
    "###### Comparison of ISOMAP and MDS when projecting onto a 2D space \n",
    "# Note: the attendees must deduce that 'n_components' = 2 (just in case)\n",
    "\n",
    "##### ----- ISOMAP EMBEDDING -----\n",
    "# Isomap Embedding\n",
    "### YOUR CODE HERE (fill in the \"None\")\n",
    "# Hint: the variable \"X_isomap_transformed\" must be the Isomap-transformed data\n",
    "None \n",
    "X_isomap_transformed = None\n",
    "### END OF YOUR CODE\n",
    "# Plot\n",
    "ax = fig.add_subplot(132)\n",
    "plt.scatter(X_isomap_transformed[:, 0], X_isomap_transformed[:, 1], c=color, cmap=plt.cm.Spectral)\n",
    "plt.title(\"ISOMAP\")\n",
    "ax.xaxis.set_major_formatter(NullFormatter())\n",
    "ax.yaxis.set_major_formatter(NullFormatter())\n",
    "plt.axis('tight')\n",
    "\n",
    "\n",
    "##### ----- MDS EMBEDDING -----\n",
    "# MDS Embedding (100 iterations)\n",
    "### YOUR CODE HERE (fill in the \"None\")\n",
    "# Hint: the variable \"X_mds_transformed\" must be the MDS-transformed data\n",
    "None\n",
    "X_mds_transformed = None\n",
    "### END OF YOUR CODE\n",
    "ax = fig.add_subplot(133)\n",
    "plt.scatter(X_mds_transformed[:, 0], X_mds_transformed[:, 1], c=color, cmap=plt.cm.Spectral)\n",
    "plt.title(\"MDS\")\n",
    "ax.xaxis.set_major_formatter(NullFormatter())\n",
    "ax.yaxis.set_major_formatter(NullFormatter())\n",
    "plt.axis('tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    " 1. https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60\n",
    " 2. https://www.kaggle.com/nirajvermafcb/principal-component-analysis-with-scikit-learn\n",
    " 3. https://cmdlinetips.com/2018/03/pca-example-in-python-with-scikit-learn/\n",
    " 4. http://benalexkeen.com/isomap-for-dimensionality-reduction-in-python/\n",
    " 5. https://jakevdp.github.io/PythonDataScienceHandbook/05.10-manifold-learning.html\n",
    " 6. Hands-on Machine Learning with Scikit-learn, Keras and Tensorflow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
